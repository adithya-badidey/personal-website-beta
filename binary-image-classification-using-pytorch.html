
<!doctype html>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

  <meta name="generator" content="TiddlyWiki" />
  <meta name="tiddlywiki-version" content="5.2.1" />

  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
  <meta name="mobile-web-app-capable" content="yes" />

  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<meta name="page_canonical_url" content="https://adithyab.in/binary-image-classification-using-pytorch" />
	<meta name="page_unique_id" content="20220704202637391" />

  <meta name="format-detection" content="telephone=no">
	<script></script>
  <link id="faviconLink" rel="shortcut icon" href="/favicon.ico">

<title>Binary Image Classification using PyTorch ~ Adithya's Lair</title>
<meta name="description" content="After previously having worked with TensorFlow, I had to switch to using pyTorch for all my deep learning work due to a project. So I replicated what I did previously in Binary Image Classification In Tensorflow using pyTorch.">

<meta property="og:type" content="article" />
<meta property="og:url" content="https://adithyab.in/binary-image-classification-using-pytorch" />
<meta property="og:title" content="Binary Image Classification using PyTorch ~ Adithya's Lair" />
<meta property="og:image" content="" />
<meta property="og:description" content="After previously having worked with TensorFlow, I had to switch to using pyTorch for all my deep learning work due to a project. So I replicated what I did previously in Binary Image Classification In Tensorflow using pyTorch." />

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@adithya_badidey">
<meta name="twitter:creator" content="@adithya_badidey">
<meta name="twitter:title" content="Binary Image Classification using PyTorch ~ Adithya's Lair" />
<meta name="twitter:description" content="After previously having worked with TensorFlow, I had to switch to using pyTorch for all my deep learning work due to a project. So I replicated what I did previously in Binary Image Classification In Tensorflow using pyTorch." />
<meta name="twitter:image" content="" />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-171642977-1"></script>

<link rel="stylesheet" href="css/atom-one-dark.min.css">
<script src="js/highlight.min.js" defer></script>
<script src="js/scripts.js" defer></script>
<link rel="stylesheet" href="css/style.css" />
</head>

<body class="tc-body">
  
<nav aria-label="main navigation" class="navbar" role="navigation">
    <div class="navbar-brand">
      <a class="navbar-item" href="/">
        Adithya's Lair
      </a>

      <a aria-expanded="false" aria-label="menu" class="navbar-burger burger" data-target="navbarTW" role="button">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>

    <div class="navbar-menu" id="navbarTW">
      <div class="navbar-end">
<a class="navbar-item" href="/">Home</a>
<a class="navbar-item" href="/blog">Blog</a>
<a class="navbar-item" href="/portfolio">Portfolio</a>
     </div>
    </div>
  </nav>


<section class="section">
    <div class="columns mt-6">
        <div class="column is-5-fullhd is-6-desktop is-8-tablet is-offset-2">
            <div class="content tc-blog">
                
                <span class="has-text-grey-light is-small tc-subtitle tc-created">
                    5th July, 2022
                </span>
                <h1 class="tc-title mt-1">
                    Binary Image Classification using PyTorch
                </h1>
                <p>After previously having worked with TensorFlow, I had to switch to using pyTorch for all my deep learning work due to a project. So I replicated what I did previously in <a class="tc-tiddlylink tc-tiddlylink-resolves" href="./binary-image-classification-in-tensorflow.html">Binary Image Classification In Tensorflow</a> using pyTorch.</p><h2>Setting up the environment &amp; Importing the dataset</h2><p>I use the the "The Oxford-IIIT Pet Dataset" from <a class="tc-tiddlylink-external" href="https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz" rel="noopener noreferrer" target="_blank">https://www.robots.ox.ac.uk/~vgg/data/pets/</a>.</p><p>Once downloaded the tarball contains a single folder called <code>images</code>, which contains both the cat and dog photos. In this particular dataset, the label of the image is in the filename. Particularly, the first letter of the filename is capital if the image were that of a cat (like <code>Persian_80.jpg</code>) and lowercase if its a dog photo (like <code>keeshond_130.jpg</code>).</p><p>So, once I extract the tarball, I move cats and dogs into their own subfolder. Once I do that the folder structure is as follows:</p><ul><li>pet_photos<ul><li>dogs<ul><li>yorkshire_terrier_93.jpg</li><li>german_shorthaired_118.jpg</li><li>...</li></ul></li><li>cats<ul><li>Bombay_75.jpg</li><li>Sphynx_84.jpg</li><li>...</li></ul></li></ul></li></ul><pre class="python hljs"><code><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">import</span> pathlib
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> torchvision
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader, random_split
<span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm

plt.style.use(<span class="hljs-string">'dark_background'</span>)

print(<span class="hljs-string">f"<span class="hljs-subst">{<span class="hljs-string">'Pytorch'</span>:&lt;<span class="hljs-number">20</span>}</span>"</span>,torch.__version__)
<span class="hljs-keyword">if</span> torch.cuda.is_available():
    device=<span class="hljs-string">'cuda'</span>

    print(<span class="hljs-string">f"<span class="hljs-subst">{<span class="hljs-string">'Device'</span>:&lt;<span class="hljs-number">20</span>}</span>"</span>, <span class="hljs-string">f"GPU (<span class="hljs-subst">{torch.cuda.get_device_name(<span class="hljs-number">0</span>)}</span>)"</span>)
    
    torch.backends.cudnn.benchmark = <span class="hljs-literal">True</span>
<span class="hljs-keyword">else</span>:
    print(<span class="hljs-string">"GPU is **not available**"</span>)
    device=<span class="hljs-string">'cpu'</span>

print()
print(<span class="hljs-string">"Looking for the dataset..."</span>)

data_dir = pathlib.Path(<span class="hljs-string">'/home/addy/datasets/pets_photos/'</span>)

<span class="hljs-keyword">if</span> data_dir.exists():
    print(<span class="hljs-string">"Found the 'pets_photos' dataset."</span>)
<span class="hljs-keyword">else</span>:
    print(<span class="hljs-string">"Downloading the 'pets_photos' dataset."</span>)
    dataset_url = <span class="hljs-string">"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz"</span>
    <span class="hljs-comment"># !wget {dataset_url} -P {data_dir.parent}</span>
    <span class="hljs-comment"># !mkdir {data_dir}</span>
    <span class="hljs-comment"># !tar xf {data_dir.parent / "images.tar.gz"} -C {data_dir}</span>
    
    <span class="hljs-comment"># Move cats and dogs into their own subfolder so that the </span>
    <span class="hljs-comment"># tf.keras.utils.image_dataset_from_directory function can pickup</span>
    <span class="hljs-comment"># categories from the folder structure.</span>

    images_dir = data_dir / <span class="hljs-string">'images'</span>
    cats_dir = data_dir / <span class="hljs-string">'cats'</span>
    dogs_dir = data_dir / <span class="hljs-string">'dogs'</span>

    cats_dir.mkdir()
    dogs_dir.mkdir()

    f = []
    <span class="hljs-keyword">for</span> (dirpath, dirnames, filenames) <span class="hljs-keyword">in</span> os.walk(images_dir):
        <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> filenames:
            <span class="hljs-comment"># The cats' image filenames start with an uppercase letter ¯\_(ツ)_/¯</span>
            <span class="hljs-keyword">if</span> file[<span class="hljs-number">0</span>].isupper():
                os.rename(images_dir / file, cats_dir / file)
            <span class="hljs-keyword">else</span>:
                os.rename(images_dir / file, dogs_dir / file)


    <span class="hljs-comment"># Finally delete the images folder. All photos should be under </span>
    <span class="hljs-comment"># their proper categorical folder.</span>
    !rm -r {data_dir / <span class="hljs-string">'images'</span>}

</code></pre><pre>Pytorch              1.10.2+cu102
Device               GPU (NVIDIA GeForce GTX 1660 Ti)

Looking for the dataset...
Found the 'pets_photos' dataset.
</pre><pre class="python hljs"><code><span class="hljs-comment"># Initializing parameters</span>

batch_size = <span class="hljs-number">32</span>     <span class="hljs-comment"># Reduce this if you get memory errors</span>

img_height = <span class="hljs-number">160</span>    <span class="hljs-comment"># I'm keeping this at 160 for no particular reason </span>
img_width = <span class="hljs-number">160</span>     <span class="hljs-comment"># (there is a reason, I'll share in a future blog post)</span>

seed = <span class="hljs-number">120</span>          <span class="hljs-comment"># A random seed to get replicable results</span>

epochs = <span class="hljs-number">10</span>         <span class="hljs-comment"># The number of training epochs</span>
</code></pre><h2>Loading the datasets</h2><p>Since the data now exists in appropriate folder structure, I can use the <code>torchvision.datasets.ImageFolder</code> to read them. Then I use <code>torch.utils.data.random_split</code> to divide the dataset into train and test sets.</p><pre class="python hljs"><code>transform_image = torchvision.transforms.Compose([
    torchvision.transforms.Resize([img_height, img_width]),
    torchvision.transforms.ToTensor()
])

transform_label = <span class="hljs-keyword">lambda</span> x: torch.tensor(float(x)).unsqueeze(<span class="hljs-number">-1</span>)

dataset = torchvision.datasets.ImageFolder(
    data_dir,
    transform=transform_image,
    target_transform=transform_label
)

len_train = int(len(dataset) * <span class="hljs-number">0.8</span>)
len_test = len(dataset) - len_train

<span class="hljs-comment">#using random_split from torch.utils.data </span>
train_dataset, test_dataset = random_split(
    dataset, [len_train, len_test], 
    generator=torch.Generator().manual_seed(seed)    )

print(<span class="hljs-string">"Images in the train set:"</span>,len(train_dataset))
print(<span class="hljs-string">"Images in the test set:"</span>,len(test_dataset))

train_dataloader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=<span class="hljs-literal">True</span>,
    num_workers=<span class="hljs-number">12</span>,
    prefetch_factor=<span class="hljs-number">3</span>)

test_dataloader = DataLoader(
    test_dataset, 
    batch_size=batch_size, 
    num_workers=<span class="hljs-number">12</span>,
    prefetch_factor=<span class="hljs-number">3</span>)

<span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_dataloader:
    print(<span class="hljs-string">"Shape of X [N, C, H, W]: "</span>, X.shape)
    print(<span class="hljs-string">"Shape of y [N, 1]:"</span>, y.shape)
    <span class="hljs-keyword">break</span>
</code></pre><pre>Images in the train set: 5912
Images in the test set: 1478
Shape of X [N, C, H, W]:  torch.Size([32, 3, 160, 160])
Shape of y [N, 1]: torch.Size([32, 1])
</pre><pre class="python hljs"><code>class_names = dataset.classes
class_names
</code></pre><pre>['cats', 'dogs']
</pre><h3>Displaying pyTorch's img tensor using matplotlib</h3><p>pyTorch reads img files into a tensor of shape <code>[3, 160, 160]</code>. However, <code>matplotlib</code> expects the shape to be in <code>[160,160,3]</code> and will throw the exception <code>TypeError: Invalid shape (3, 160, 240) for image data</code> if called directly.</p><pre class="python hljs"><code><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_dataloader:
    img = X[<span class="hljs-number">0</span>]
    <span class="hljs-keyword">break</span>

img.shape, np.transpose(img.numpy(), (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)).shape
</code></pre><pre>(torch.Size([3, 160, 160]), (160, 160, 3))
</pre><p>Calling <code>np.transpose(img.numpy(), (1, 2, 0))</code> returns an array which fits the matplotlib expectation of an image.</p><h2>Verifying the dataloader</h2><p>I visualize a small number of items from the train dataloader to make sure that the images look as they should</p><pre class="python hljs"><code>class_names = list(train_dataset.dataset.class_to_idx.keys())

fig = plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>))
<span class="hljs-keyword">for</span> images, labels <span class="hljs-keyword">in</span> train_dataloader:
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">9</span>):        
        ax = plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, i + <span class="hljs-number">1</span>)
        img = np.transpose(images[i].numpy(), (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>))
        plt.imshow(img)
        plt.title(class_names[int(labels[i].item())])
        plt.axis(<span class="hljs-string">"off"</span>)
    <span class="hljs-keyword">break</span>
        

plt.show()

</code></pre><p><img src="files/10-pet-classif-basic_10_0.png" title="png"></p><h2>Modelling</h2><p>We create a simple model consisting of:</p><ul><li>3 convolution blocks with a max pooling operation after</li><li>1 linear layer with 128 units</li><li>1 linear layer which outputs one binary value (dog or cat)</li></ul><pre class="python hljs"><code><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BinaryNet</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super().__init__()
        self.conv1 = nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">16</span>, <span class="hljs-number">3</span>)
        self.pool = nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
        self.conv2 = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">32</span>, <span class="hljs-number">3</span>)
        self.conv3 = nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">3</span>)
        self.fc1 = nn.Linear(<span class="hljs-number">64</span> * <span class="hljs-number">81</span> * <span class="hljs-number">4</span>, <span class="hljs-number">128</span>)
        self.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">1</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = torch.flatten(x, <span class="hljs-number">1</span>) <span class="hljs-comment"># flatten all dimensions except batch</span>
        x = F.relu(self.fc1(x))
        x = torch.sigmoid(self.fc2(x))
        <span class="hljs-keyword">return</span> x

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_loop</span><span class="hljs-params">(dataloader, model, loss_fn, optimizer, history)</span>:</span>
    size = len(dataloader.dataset)
    accuracy = <span class="hljs-number">0</span>
    <span class="hljs-keyword">for</span> batch, (X, y) <span class="hljs-keyword">in</span> enumerate(dataloader):
        X = X.to(device)
        y = y.to(device)
        
        <span class="hljs-comment">#FORWARD PASS</span>
        pred = model(X)
        loss = loss_fn(pred, y)

        <span class="hljs-comment"># Backpropagation</span>
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        loss = loss.item()
        accuracy += (torch.round(pred) == y).type(torch.float).sum().item()

        <span class="hljs-comment"># if batch % 100 == 0:</span>
        <span class="hljs-comment">#     loss, current = loss.item(), batch * len(X)</span>
        <span class="hljs-comment">#     print(f"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]")</span>
    accuracy /= size
    history[<span class="hljs-string">'train_loss'</span>].append(loss)
    history[<span class="hljs-string">'train_accuracy'</span>].append(accuracy)
    <span class="hljs-keyword">return</span> loss, accuracy


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_loop</span><span class="hljs-params">(dataloader, model, loss_fn, history)</span>:</span>
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    loss, accuracy = <span class="hljs-number">0</span>, <span class="hljs-number">0</span>

    <span class="hljs-keyword">with</span> torch.no_grad():
        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> dataloader:
            X = X.to(device)
            y = y.to(device)
            
            pred = model(X)
            
            loss += loss_fn(pred, y).item()
            accuracy += (torch.round(pred) == y).type(torch.float).sum().item()

    loss /= num_batches
    accuracy /= size

    history[<span class="hljs-string">'test_loss'</span>].append(loss)
    history[<span class="hljs-string">'test_accuracy'</span>].append(accuracy)
    <span class="hljs-keyword">return</span> loss, accuracy
</code></pre><p>We train this model for 10 epochs with an Adam optimizer with default lr (1e-3) and a BCELoss (Binary Cross Entropy Loss).</p><pre class="python hljs"><code>model = BinaryNet().to(device)
    
loss_fn = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters())


epochs = <span class="hljs-number">10</span>
history = {
    <span class="hljs-string">'train_loss'</span>:[],
    <span class="hljs-string">'train_accuracy'</span>:[],
    <span class="hljs-string">'test_loss'</span>:[],
    <span class="hljs-string">'test_accuracy'</span>:[]
}

<span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> tqdm(range(epochs), bar_format=<span class="hljs-string">"{elapsed} Elapsed | {percentage:3.0f}% done |{bar}| {n_fmt}/{total_fmt} [{remaining} remaining | {rate_fmt}{postfix}]"</span>, unit=<span class="hljs-string">"epoch"</span>, total=epochs):
    train_loop(train_dataloader, model, loss_fn, optimizer, history)
    test_loop(test_dataloader, model, loss_fn, history)
</code></pre><pre>01:04 Elapsed | 100% done |██████████| 10/10 [00:00 remaining |  6.49s/epoch]
</pre><p>Finally, we visualize the training and validation accuracy and loss.</p><pre class="python hljs"><code>epochs_range = range(epochs)

plt.figure(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>))
plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)
plt.plot(epochs_range, history[<span class="hljs-string">'train_accuracy'</span>], label=<span class="hljs-string">'Training Accuracy'</span>, color=<span class="hljs-string">'#03CEA4'</span>)
plt.plot(epochs_range, history[<span class="hljs-string">'test_accuracy'</span>], label=<span class="hljs-string">'Validation Accuracy'</span>, color=<span class="hljs-string">'#fc00ff'</span>)
plt.legend(loc=<span class="hljs-string">'lower right'</span>)
plt.title(<span class="hljs-string">'Training and Validation Accuracy'</span>)

plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
plt.plot(epochs_range, history[<span class="hljs-string">'train_loss'</span>], label=<span class="hljs-string">'Training Loss'</span>, color=<span class="hljs-string">'#03CEA4'</span>)
plt.plot(epochs_range, history[<span class="hljs-string">'test_loss'</span>], label=<span class="hljs-string">'Validation Loss'</span>, color=<span class="hljs-string">'#fc00ff'</span>)
plt.legend(loc=<span class="hljs-string">'lower left'</span>)
plt.title(<span class="hljs-string">'Training and Validation Loss'</span>)
plt.show()

</code></pre><p><img src="files/10-pet-classif-basic-pytorch_16_0.png" title="image"></p><p>The validation loss increases after the 5th epoch or so. This is because the model is over-fitting to the training data.</p>
            </div>
            <div class="tc-blog-footer">
                <hr class="mb-2">
                <nav class="tc-backlinks mb-4">
                    <h2 class="backlinks-header">
                        
                    </h2>
                    <div class="content">
                        <ul>
                            
                        </ul>
                    </div>
                </nav>
                <nav class="level is-mobile">
                    
                    <div class="level-left">
                        <p class="is-size-7 has-text-grey-light is-small tc-modified tc-subtitle">Last Updated: 
                            5th July, 2022
                        </p>
                    </div>
                    <div class="level-right">
                        <div class="tags">
                            
                                <span class="tag">
                                    deep learning
                                </span>
                            
                        </div>
                    </div>
                </nav>
                <hr>
            </div>
            <div id="disqus_thread"></div>
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
    </div>
</section>

<footer class="footer">
  <div class="columns">
	  <div class="column is-6-desktop is-8-tablet is-offset-2"><p><p>
Built with <a class="tc-tiddlylink-external" href="https://tiddlyjam.com" rel="noopener noreferrer" target="_blank">TiddlyJam</a> and <a class="tc-tiddlylink-external" href="https://bulma.io/" rel="noopener noreferrer" target="_blank">Bulma</a>. Hosted on <a class="tc-tiddlylink-external" href="https://pages.github.com/" rel="noopener noreferrer" target="_blank">Github Pages</a>.
    </p>
		</p></div>
  </div>
	<link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;600&amp;display=swap" rel="stylesheet">
</footer>

</body>
</html>
